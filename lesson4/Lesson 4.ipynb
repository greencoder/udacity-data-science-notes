{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of Rainy Days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function should run a SQL query on a dataframe of weather data.  The SQL query should return one column and one row - a count of the number of days in the dataframe where the rain column is equal to 1 (i.e., the number of days it rained).  The dataframe will be titled `weather_data`. You'll need to provide the SQL query.  You might find SQL's `count` function useful for this exercise.  You can read more about it here:\n",
    "    \n",
    "https://dev.mysql.com/doc/refman/5.1/en/counting-rows.html\n",
    "    \n",
    "You might also find that interpreting numbers as integers or floats may not work initially.  In order to get around this issue, it may be useful to cast these numbers as integers.  This can be done by writing `cast(column as integer)`.\n",
    "\n",
    "So for example, if we wanted to cast the `maxtempi` column as an integer, we would actually write something like `where cast(maxtempi as integer) = 76`, as opposed to simply `where maxtempi = 76`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count(rain)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count(rain)\n",
       "0           10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "import pandasql\n",
    "\n",
    "def num_rainy_days(filename):\n",
    "    weather_data = pandas.read_csv(filename)\n",
    "    q = \"\"\"\n",
    "    SELECT COUNT(rain) FROM weather_data WHERE cast(rain as integer) = 1\n",
    "    \"\"\"\n",
    "    rainy_days = pandasql.sqldf(q.lower(), locals())\n",
    "    return rainy_days\n",
    "\n",
    "num_rainy_days('weather_underground.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temp on Foggy and Nonfoggy Days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function should run a SQL query on a dataframe of weather data.  The SQL query should return two columns and two rows - whether it was foggy or not (0 or 1) and the max `maxtempi` for that fog value (i.e., the maximum max temperature for both foggy and non-foggy days).  The dataframe will be titled `weather_data`. You'll need to provide the SQL query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fog</th>\n",
       "      <th>max(maxtempi)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fog  max(maxtempi)\n",
       "0    0             86\n",
       "1    1             81"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def max_temp_aggregate_by_fog(filename):\n",
    "    weather_data = pandas.read_csv(filename)\n",
    "    q = \"\"\"\n",
    "    SELECT fog, max(maxtempi) FROM weather_data GROUP BY fog\n",
    "    \"\"\"\n",
    "    foggy_days = pandasql.sqldf(q.lower(), locals())\n",
    "    return foggy_days\n",
    "\n",
    "max_temp_aggregate_by_fog('weather_underground.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Temp on Weekends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function should run a SQL query on a dataframe of weather data.  The SQL query should return one column and one row - the average `meantempi` on days that are a Saturday or Sunday (i.e., the the average mean temperature on weekends). The dataframe will be titled `weather_data` and you can access the date in the dataframe via the `date` column.\n",
    "\n",
    "You'll need to provide the SQL query.\n",
    "\n",
    "Also, you can convert dates to days of the week via the `strftime` keyword in SQL. For example, `cast(strftime('%w', date) as integer)` will return `0` if the date is a Sunday or `6` if the date is a Saturday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg(meantempi)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65.111111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg(meantempi)\n",
       "0       65.111111"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def avg_weekend_temperature(filename):\n",
    "    weather_data = pandas.read_csv(filename)\n",
    "    q = \"\"\"\n",
    "    SELECT avg(meantempi) FROM weather_data WHERE cast(strftime('%w', date) as integer) IN (0,6)\n",
    "    \"\"\"\n",
    "    mean_temp_weekends = pandasql.sqldf(q.lower(), locals())\n",
    "    return mean_temp_weekends\n",
    "\n",
    "avg_weekend_temperature('weather_underground.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Temp on Rainy Days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function should run a SQL query on a dataframe of weather data. More specifically you want to find the average minimum temperature (`mintempi` column of the weather dataframe) on rainy days where the minimum temperature is greater than 55 degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg(mintempi)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg(mintempi)\n",
       "0          61.25"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def avg_min_temperature(filename):\n",
    "    weather_data = pandas.read_csv(filename)\n",
    "    q = \"\"\"\n",
    "    SELECT avg(mintempi) FROM weather_data WHERE cast(rain as integer) = 1 AND mintempi > 55\n",
    "    \"\"\"\n",
    "    avg_min_temp_rainy = pandasql.sqldf(q.lower(), locals())\n",
    "    return avg_min_temp_rainy\n",
    "\n",
    "avg_min_temperature('weather_underground.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix Turnstile Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You want to write a function that will update each row in the text file so there is only one entry per row. A few examples below:\n",
    "```\n",
    "A002,R051,02-00-00,05-28-11,00:00:00,REGULAR,003178521,001100739\n",
    "A002,R051,02-00-00,05-28-11,04:00:00,REGULAR,003178541,001100746\n",
    "A002,R051,02-00-00,05-28-11,08:00:00,REGULAR,003178559,001100775\n",
    "```\n",
    "\n",
    "Write the updates to a different text file in the format of `updated_ + filename`. For example:\n",
    "1. if you read in a text file called `turnstile_110521.txt`\n",
    "1. you should write the updated data to `updated_turnstile_110521.txt`\n",
    "\n",
    "The order of the fields should be preserved. \n",
    "\n",
    "You can see a sample of the turnstile text file that's passed into the function and the the corresponding updated file by downloading these files from the resources:\n",
    "\n",
    "1. Sample input file: `turnstile_110528.txt`\n",
    "1. Sample updated file: `solution_turnstile_110528.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the basic code that will get run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "file_in = open('turnstile_110507.txt', 'r')\n",
    "file_out = open('updated_turnstile_110507.txt', 'w')\n",
    "\n",
    "csv_reader = csv.reader(file_in)\n",
    "csv_writer = csv.writer(file_out)\n",
    "    \n",
    "# Keep a list of all the output rows we create\n",
    "output_rows = []\n",
    "\n",
    "# Iterate over each row of the CSV file\n",
    "for row in csv_reader:\n",
    "    \n",
    "    # Get the first three items for each row. Using pop()\n",
    "    # will remove them from the list, leaving a set of\n",
    "    # values divisible by 5. Each set of five values\n",
    "    # we wil call a \"chunk\"\n",
    "    el1 = row.pop(0)\n",
    "    el2 = row.pop(0)\n",
    "    el3 = row.pop(0)\n",
    "    \n",
    "    # Figure out how many \"chunks\" of five elements are left\n",
    "    number_of_chunks = len(row) / 5\n",
    "    \n",
    "    # Iterate over each \"chunk\" of elements\n",
    "    for chunk_index in range(0, number_of_chunks):\n",
    "        start_index = chunk_index * 5\n",
    "        end_index = start_index + 5\n",
    "        combined_row = [el1, el2, el3] + row[start_index: end_index]\n",
    "        output_rows.append(combined_row)\n",
    "\n",
    "# Write the output\n",
    "csv_writer.writerows(output_rows)\n",
    "\n",
    "# Close the file handles that are open\n",
    "file_in.close()\n",
    "file_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fix_turnstile_data(filenames):\n",
    "\n",
    "    for filename in filenames:\n",
    "        \n",
    "        file_in = open(filename, 'r')\n",
    "        file_out = open('updated_' + filename, 'w')\n",
    "        csv_reader = csv.reader(file_in)\n",
    "        csv_writer = csv.writer(file_out)\n",
    "    \n",
    "        # Keep a list of all the output rows we create\n",
    "        output_rows = []\n",
    "\n",
    "        # Iterate over each row of the CSV file\n",
    "        for row in csv_reader:\n",
    "    \n",
    "            # Get the first three items for each row. Using pop()\n",
    "            # will remove them from the list, leaving a set of\n",
    "            # values divisible by 5. Each set of five values\n",
    "            # we wil call a \"chunk\"\n",
    "            el1 = row.pop(0)\n",
    "            el2 = row.pop(0)\n",
    "            el3 = row.pop(0)\n",
    "\n",
    "            # Figure out how many \"chunks\" of five elements are left\n",
    "            number_of_chunks = len(row) / 5\n",
    "\n",
    "            # Iterate over each \"chunk\" of five elements. This can be \n",
    "            # hard to visualize, it would look something like this:\n",
    "            # \n",
    "            #       Chunk One           Chunk Two\n",
    "            # ┌──────────────────┐┌──────────────────┐\n",
    "            # 'a','b','c','d','e','f','g','h','i','j'\n",
    "            #\n",
    "            \n",
    "            for chunk_index in range(0, number_of_chunks):\n",
    "                start_index = chunk_index * 5\n",
    "                end_index = start_index + 5\n",
    "                combined_row = [el1, el2, el3] + row[start_index: end_index]\n",
    "                output_rows.append(combined_row)\n",
    "\n",
    "        # Write the output\n",
    "        csv_writer.writerows(output_rows)        \n",
    "                \n",
    "        # Close the files we have open\n",
    "        file_in.close()\n",
    "        file_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Turnstile Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that takes the files in the list `filenames`, which all have the columns `C/A, UNIT, SCP, DATEn, TIMEn, DESCn, ENTRIESn, EXITSn`, and consolidates them into one file located at output_file.  There should be ONE row with the column headers, located at the top of the file. The input files do not have column header rows of their own.\n",
    "    \n",
    "For example, if file_1 has:\n",
    "```\n",
    "line 1 ...\n",
    "line 2 ...\n",
    "```\n",
    "\n",
    "and another file, file_2 has:\n",
    "```\n",
    "line 3 ...\n",
    "line 4 ...\n",
    "line 5 ...\n",
    "```\n",
    "\n",
    "We need to combine file_1 and file_2 into a master_file like below:\n",
    "```\n",
    "C/A, UNIT, SCP, DATEn, TIMEn, DESCn, ENTRIESn, EXITSn\n",
    "line 1 ...\n",
    "line 2 ...\n",
    "line 3 ...\n",
    "line 4 ...\n",
    "line 5 ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_master_turnstile_file(filenames, output_file):\n",
    "    with open(output_file, 'w') as master_file:\n",
    "        master_file.write('C/A,UNIT,SCP,DATEn,TIMEn,DESCn,ENTRIESn,EXITSn\\n')\n",
    "        for filename in filenames:\n",
    "            with open(filename, 'r') as f:\n",
    "                for line in f.readlines():\n",
    "                    master_file.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixing Irregular Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function should read the csv file located at `filename` into a pandas dataframe, and filter the dataframe to only rows where the `DESCn` column has the value `REGULAR`.\n",
    "    \n",
    "For example, if the pandas dataframe is as follows:\n",
    "```\n",
    ",C/A,UNIT,SCP,DATEn,TIMEn,DESCn,ENTRIESn,EXITSn\n",
    "0,A002,R051,02-00-00,05-01-11,00:00:00,REGULAR,3144312,1088151\n",
    "1,A002,R051,02-00-00,05-01-11,04:00:00,DOOR,3144335,1088159\n",
    "2,A002,R051,02-00-00,05-01-11,08:00:00,REGULAR,3144353,1088177\n",
    "3,A002,R051,02-00-00,05-01-11,12:00:00,DOOR,3144424,1088231\n",
    "```\n",
    "\n",
    "The dataframe will look like below after filtering to only rows where `DESCn` column has the value `REGULAR`:\n",
    "```\n",
    "0,A002,R051,02-00-00,05-01-11,00:00:00,REGULAR,3144312,1088151\n",
    "2,A002,R051,02-00-00,05-01-11,08:00:00,REGULAR,3144353,1088177\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "def filter_by_regular(filename):\n",
    "    turnstile_df = pandas.read_csv(filename)\n",
    "    filtered_df = turnstile_df[turnstile_df['DESCn'] == 'REGULAR']\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Hourly Entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data in the MTA Subway Turnstile data reports on the cumulative number of entries and exits per row.  Assume that you have a dataframe called `df` that contains only the rows for a particular turnstile machine\n",
    "(i.e., unique `SCP`, `C/A`, and `UNIT`). This function should change these cumulative entry numbers to a count of entries since the last reading (i.e., entries since the last row in the dataframe).\n",
    "    \n",
    "More specifically, you want to do two things:\n",
    "1. Create a new column called `ENTRIESn_hourly`\n",
    "2. Assign to the column the difference between `ENTRIESn` of the current row  and the previous row. If there is any `NaN`, fill/replace it with 1.\n",
    "    \n",
    "You may find the pandas functions `shift()` and `fillna()` to be helpful in this exercise.\n",
    "    \n",
    "Examples of what your dataframe should look like at the end of this exercise:\n",
    "```    \n",
    "       C/A  UNIT       SCP     DATEn     TIMEn    DESCn  ENTRIESn    EXITSn  ENTRIESn_hourly\n",
    "0     A002  R051  02-00-00  05-01-11  00:00:00  REGULAR   3144312   1088151                1\n",
    "1     A002  R051  02-00-00  05-01-11  04:00:00  REGULAR   3144335   1088159               23\n",
    "2     A002  R051  02-00-00  05-01-11  08:00:00  REGULAR   3144353   1088177               18\n",
    "3     A002  R051  02-00-00  05-01-11  12:00:00  REGULAR   3144424   1088231               71\n",
    "4     A002  R051  02-00-00  05-01-11  16:00:00  REGULAR   3144594   1088275              170\n",
    "5     A002  R051  02-00-00  05-01-11  20:00:00  REGULAR   3144808   1088317              214\n",
    "6     A002  R051  02-00-00  05-02-11  00:00:00  REGULAR   3144895   1088328               87\n",
    "7     A002  R051  02-00-00  05-02-11  04:00:00  REGULAR   3144905   1088331               10\n",
    "8     A002  R051  02-00-00  05-02-11  08:00:00  REGULAR   3144941   1088420               36\n",
    "9     A002  R051  02-00-00  05-02-11  12:00:00  REGULAR   3145094   1088753              153\n",
    "10    A002  R051  02-00-00  05-02-11  16:00:00  REGULAR   3145337   1088823              243\n",
    "...\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hourly_entries(df):\n",
    "    df['ENTRIESn_hourly'] = df['ENTRIESn'] - df['ENTRIESn'].shift(1)\n",
    "    df['ENTRIESn_hourly'].fillna(1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Hourly Exits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data in the MTA Subway Turnstile data reports on the cumulative number of entries and exits per row.  Assume that you have a dataframe called `df` that contains only the rows for a particular turnstile machine\n",
    "(i.e., unique SCP, C/A, and UNIT).  This function should change these cumulative exit numbers to a count of exits since the last reading (i.e., exits since the last row in the dataframe).\n",
    "    \n",
    "More specifically, you want to do two things:\n",
    "1. Create a new column called `EXITSn_hourly`\n",
    "2. Assign to the column the difference between `EXITSn` of the current row and the previous row. If there is any `NaN`, fill/replace it with `0`.\n",
    "    \n",
    "You may find the pandas functions `shift()` and `fillna()` to be helpful in this exercise.\n",
    "    \n",
    "Example dataframe below: (several columns omitted for brevity)\n",
    "```\n",
    "      Unnamed: 0   C/A  UNIT  ...  ENTRIESn    EXITSn  ENTRIESn_hourly  EXITSn_hourly\n",
    "0              0  A002  R051  ...   3144312   1088151                0              0\n",
    "1              1  A002  R051  ...   3144335   1088159               23              8\n",
    "2              2  A002  R051  ...   3144353   1088177               18             18\n",
    "3              3  A002  R051  ...   3144424   1088231               71             54\n",
    "4              4  A002  R051  ...   3144594   1088275              170             44\n",
    "5              5  A002  R051  ...   3144808   1088317              214             42\n",
    "6              6  A002  R051  ...   3144895   1088328               87             11\n",
    "7              7  A002  R051  ...   3144905   1088331               10              3\n",
    "8              8  A002  R051  ...   3144941   1088420               36             89\n",
    "9              9  A002  R051  ...   3145094   1088753              153            333\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hourly_exits(df):\n",
    "    df['EXITSn_hourly'] = df['EXITSn'] - df['EXITSn'].shift(1)\n",
    "    df['EXITSn_hourly'].fillna(0, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time to Hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given an input variable time that represents time in the format of:\n",
    "```\n",
    "\"00:00:00\" (hour:minutes:seconds)\n",
    "```\n",
    "    \n",
    "Write a function to extract the hour part from the input variable time and return it as an integer. \n",
    "\n",
    "For example:\n",
    "1. if hour is `00`, your code should return `0`\n",
    "2. if hour is `01`, your code should return `1`\n",
    "3. if hour is `21`, your code should return `21`\n",
    "        \n",
    "Please return hour as an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_to_hour(time):\n",
    "    return int(time.split(':')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reformat Subway Dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dates in our subway data are formatted in the format `month-day-year`. The dates in our weather underground data are formatted `year-month-day`.    \n",
    "\n",
    "In order to join these two data sets together, we'll want the dates formatted the same way.  Write a function that takes as its input a date in the MTA Subway data format, and returns a date in the weather underground format.\n",
    "    \n",
    "Hint: There are a couple of useful functions in the datetime library that will help on this assignment, called `strptime` and `strftime`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2000-05-01'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def reformat_subway_dates(date_string):\n",
    "    date = datetime.strptime(date_string, '%m-%d-%y')\n",
    "    date_formatted = date.strftime('%Y-%m-%d')\n",
    "    return date_formatted\n",
    "\n",
    "reformat_subway_dates('05-01-2000')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
